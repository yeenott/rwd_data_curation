{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tutorial-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "#import pyspark as ps\n",
    "#spark = (ps.sql.SparkSession.builder\n",
    "#        .appName(\"sandbox\")\n",
    "#        .getOrCreate()\n",
    "#        )\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print(spark.version)\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The csv files are stored in a folder named data in the current working directory\n",
    "DATA_DIR = os.path.join('..',\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-turkish",
   "metadata": {},
   "source": [
    "# 1. Load data and check data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-romance",
   "metadata": {},
   "source": [
    "## 1.1 Patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "breeding-address",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt_id</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13151</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43463</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42834</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37531</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31613</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pt_id     sex\n",
       "0  13151  Female\n",
       "1  43463  Female\n",
       "2  42834    Male\n",
       "3  37531  Female\n",
       "4  31613  Female"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(945, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pt_id     int64\n",
       "sex      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pt = pd.read_csv(os.path.join(DATA_DIR, 'patient.csv'), sep='\\t')\n",
    "data_pt.rename(columns={'patientid': 'pt_id'}, inplace=True)\n",
    "data_pt.head()\n",
    "data_pt.shape\n",
    "data_pt.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-tennis",
   "metadata": {},
   "source": [
    "> -----------------------------------------------------------pyspark -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regular-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|pt_id|   sex|\n",
      "+-----+------+\n",
      "|13151|Female|\n",
      "|43463|Female|\n",
      "|42834|  Male|\n",
      "|37531|Female|\n",
      "|31613|Female|\n",
      "+-----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "(945, 2)\n",
      "root\n",
      " |-- pt_id: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spdf_pt = spark.read.load(os.path.join(DATA_DIR, 'patient.csv'), format='csv', sep='\\t', inferSchema=\"true\", header='true')\n",
    "spdf_pt = spdf_pt.withColumnRenamed('patientid', 'pt_id')\n",
    "spdf_pt.show(5)\n",
    "print((spdf_pt.count(), len(spdf_pt.columns)))\n",
    "spdf_pt.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-wrestling",
   "metadata": {},
   "source": [
    "> ----------------------------Pandas Profiling----------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "id": "least-trail",
   "metadata": {},
   "source": [
    "import sweetviz as sv\n",
    "report = sv.analyze(data_pt, target_feat='pt_id')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "closed-eagle",
   "metadata": {},
   "source": [
    "report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-reserve",
   "metadata": {},
   "source": [
    "#### Check and remove the duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-membrane",
   "metadata": {},
   "source": [
    "#### Note: there are patients with multiple sex values. Remove those duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "great-invite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(932, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pt.drop_duplicates(subset=['pt_id'], inplace=True)\n",
    "data_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "warming-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pt_id    932\n",
       "sex        8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Female          515\n",
       "Male            384\n",
       "male             10\n",
       "Not Reported      9\n",
       "female            9\n",
       "f                 3\n",
       "M                 1\n",
       "m                 1\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_pt.apply(lambda x: len(x.unique()))\n",
    "data_pt.nunique()\n",
    "data_pt.sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-occurrence",
   "metadata": {},
   "source": [
    "> -----------------------------------------------------------pyspark -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "copyrighted-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(932, 2)\n",
      "+------------+-----+\n",
      "|         sex|count|\n",
      "+------------+-----+\n",
      "|      Female|  515|\n",
      "|        Male|  384|\n",
      "|        male|   10|\n",
      "|Not Reported|    9|\n",
      "|      female|    9|\n",
      "|           f|    3|\n",
      "|           m|    1|\n",
      "|           M|    1|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spdf_pt = spdf_pt.dropDuplicates(['pt_id'])\n",
    "print((spdf_pt.count(), len(spdf_pt.columns)))\n",
    "#from pyspark.sql import functions as F\n",
    "#df1 = spdf_pt.groupby(\"sex\").agg(F.count(\"pt_id\").alias(\"gender\"))\n",
    "spdf_pt.groupby(\"sex\").count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-physics",
   "metadata": {},
   "source": [
    "#### We standardize the values of sex, F for Female, M for Male, N for Not Reported. The gender distribution is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solid-background",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    527\n",
       "M    396\n",
       "N      9\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pt['sex'] = data_pt['sex'].astype(str).str.upper().str[0]\n",
    "data_pt.sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-institute",
   "metadata": {},
   "source": [
    "> -----------------------------------------------------------pyspark -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|         sex|count|\n",
      "+------------+-----+\n",
      "|      Female|  515|\n",
      "|        Male|  384|\n",
      "|        male|   10|\n",
      "|      female|    9|\n",
      "|Not Reported|    9|\n",
      "|           f|    3|\n",
      "|           m|    1|\n",
      "|           M|    1|\n",
      "+------------+-----+\n",
      "\n",
      "+--------------+-----+\n",
      "|unified_gender|count|\n",
      "+--------------+-----+\n",
      "|             F|  527|\n",
      "|             M|  396|\n",
      "|             N|    9|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "spdf_pt = spdf_pt.withColumn(\"unified_gender\", upper(spdf_pt.sex.substr(1, 1)))\n",
    "spdf_pt.groupby('sex').count().orderBy('count', ascending=False).show()\n",
    "spdf_pt.groupby('unified_gender').count().orderBy('count', ascending=False).show()\n",
    "#spdf_pt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "centered-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Value Summary\n",
      "-----------------------------------\n",
      "pt_id    0\n",
      "sex      0\n",
      "dtype: int64\n",
      "There were no rows with missing data\n"
     ]
    }
   ],
   "source": [
    "#Check missing values in specified columns.  \n",
    "columns_to_check =['pt_id', 'sex']\n",
    "row_with_missing = [row_idx for row_idx, row in data_pt[columns_to_check].isnull().iterrows() if True in row.values]\n",
    "print(\"\\nMissing Value Summary\\n{}\".format(\"-\"*35))\n",
    "print(data_pt.isnull().sum(axis = 0))\n",
    "if len(row_with_missing) > 0:\n",
    "    print(\"There were {} rows with missing diagnosis in data_pct dataset\".format(len(row_with_missing)))\n",
    "else:\n",
    "    print(\"There were no rows with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-console",
   "metadata": {},
   "source": [
    "> -----------------------------------------------------------pyspark -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prescribed-calcium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+--------------+\n",
      "|pt_id|sex|unified_gender|\n",
      "+-----+---+--------------+\n",
      "|    0|  0|             0|\n",
      "+-----+---+--------------+\n",
      "\n",
      "+-----+---+--------------+\n",
      "|pt_id|sex|unified_gender|\n",
      "+-----+---+--------------+\n",
      "|    0|  0|             0|\n",
      "+-----+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "spdf_pt.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in spdf_pt.columns]).show()\n",
    "spdf_pt.select([count(when(col(c)=='null', c)).alias(c) for c in spdf_pt.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-novel",
   "metadata": {},
   "source": [
    "## 1.2. Check diagnosis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "broadband-taste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt_id</th>\n",
       "      <th>dos</th>\n",
       "      <th>dx_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13151</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>H35.3231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13151</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>H35.3231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13151</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>H35.3220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13151</td>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>H35.3220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13151</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>H35.3220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pt_id         dos   dx_code\n",
       "0  13151  2018-04-10  H35.3231\n",
       "1  13151  2018-05-22  H35.3231\n",
       "2  13151  2018-07-17  H35.3220\n",
       "3  13151  2018-09-25  H35.3220\n",
       "4  13151  2018-12-18  H35.3220"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4672, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pt_id       int64\n",
       "dos        object\n",
       "dx_code    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dx = pd.read_csv(os.path.join(DATA_DIR, 'diagnosis.csv'), sep='\\t')\n",
    "data_dx.head()\n",
    "data_dx.shape\n",
    "data_dx.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alone-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dos type to datatime and creat a new column of year \n",
    "data_dx[\"dos\"] = pd.to_datetime(data_dx['dos'])\n",
    "data_dx['year']=data_dx['dos'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "about-daughter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4484, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dx.drop_duplicates(inplace=True)\n",
    "data_dx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-essex",
   "metadata": {},
   "source": [
    " > -------------------------------Pandas profiling tools-------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dimensional-steel",
   "metadata": {},
   "source": [
    "report = sv.analyze(data_dx)\n",
    "report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-journal",
   "metadata": {},
   "source": [
    "#### There are 152 diagnosis codes. The top 3 are H35.32, 362.52, E11.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "textile-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pt_id      932\n",
       "dos        685\n",
       "dx_code    152\n",
       "year         7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "H35.32       402\n",
       "362.52       395\n",
       "E11.9        244\n",
       "H35.033      197\n",
       "H35.3220     155\n",
       "            ... \n",
       "60189009       1\n",
       "H35.322        1\n",
       "369.9          1\n",
       "312956001      1\n",
       "36252          1\n",
       "Name: dx_code, Length: 152, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dx.apply(lambda x: len(x.unique()))\n",
    "data_dx.dx_code.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "seeing-discussion",
   "metadata": {},
   "source": [
    "data_dx.dx_code.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "natural-george",
   "metadata": {},
   "source": [
    "data_dx.dos.value_counts()\n",
    "data_dx.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "reported-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dos type to datatime and creat a new column of year \n",
    "data_dx[\"dos\"] = pd.to_datetime(data_dx['dos'])\n",
    "data_dx['year']=data_dx['dos'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caroline-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Value Summary\n",
      "-----------------------------------\n",
      "pt_id      0\n",
      "dos        0\n",
      "dx_code    0\n",
      "year       0\n",
      "dtype: int64\n",
      "There were no rows with missing data\n"
     ]
    }
   ],
   "source": [
    "#Check missing values in specified columns. Note the missing value in Treatment Plan is not counted. \n",
    "columns_to_check =['pt_id', 'dos', 'dx_code']\n",
    "row_with_missing = [row_idx for row_idx, row in data_dx[columns_to_check].isnull().iterrows() if True in row.values]\n",
    "print(\"\\nMissing Value Summary\\n{}\".format(\"-\"*35))\n",
    "print(data_dx.isnull().sum(axis = 0))\n",
    "if len(row_with_missing) > 0:\n",
    "    print(\"There were {} rows with missing diagnosis in data_pct dataset\".format(len(row_with_missing)))\n",
    "else:\n",
    "    print(\"There were no rows with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-breast",
   "metadata": {},
   "source": [
    "> -----------------------------------------------------------pyspark -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adjustable-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------+\n",
      "|pt_id|       dos| dx_code|\n",
      "+-----+----------+--------+\n",
      "|13151|2018-04-10|H35.3231|\n",
      "|13151|2018-05-22|H35.3231|\n",
      "|13151|2018-07-17|H35.3220|\n",
      "|13151|2018-09-25|H35.3220|\n",
      "|13151|2018-12-18|H35.3220|\n",
      "+-----+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- pt_id: integer (nullable = true)\n",
      " |-- dos: string (nullable = true)\n",
      " |-- dx_code: string (nullable = true)\n",
      "\n",
      "(4672, 3)\n"
     ]
    }
   ],
   "source": [
    "spdf_dx = spark.read.load(os.path.join(DATA_DIR, 'diagnosis.csv'), format='csv', sep='\\t', inferSchema=\"true\", header='true')\n",
    "#spdf_dx = spdf_pt.withColumnRenamed('patientid', 'pt_id')\n",
    "spdf_dx.show(5)\n",
    "spdf_dx.printSchema()\n",
    "print((spdf_dx.count(), len(spdf_dx.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "endangered-construction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4484, 3)\n"
     ]
    }
   ],
   "source": [
    "spdf_dx = spdf_dx.dropDuplicates()\n",
    "print((spdf_dx.count(), len(spdf_dx.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "every-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------+----+\n",
      "|pt_id|       dos| dx_code|year|\n",
      "+-----+----------+--------+----+\n",
      "|37531|2019-07-23| H35.321|2019|\n",
      "|49241|2019-04-18|H35.3220|2019|\n",
      "|30912|2016-11-01| H35.051|2016|\n",
      "|16194|2016-12-08| H35.031|2016|\n",
      "|14289|2017-12-04|  H35.32|2017|\n",
      "+-----+----------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "from pyspark.sql.types import DateType\n",
    "spdf_dx = spdf_dx.withColumn(\"year\", year(spdf_dx.dos.cast(DateType())))\n",
    "spdf_dx.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "statewide-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+----+\n",
      "|pt_id|dos|dx_code|year|\n",
      "+-----+---+-------+----+\n",
      "|    0|  0|      0|   0|\n",
      "+-----+---+-------+----+\n",
      "\n",
      "+-----+---+-------+----+\n",
      "|pt_id|dos|dx_code|year|\n",
      "+-----+---+-------+----+\n",
      "|    0|  0|      0|   0|\n",
      "+-----+---+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col, isnull\n",
    "spdf_dx.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in spdf_dx.columns]).show()\n",
    "spdf_dx.select([count(when(col(c)=='null', c)).alias(c) for c in spdf_dx.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fleet-testament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| dx_code|count|\n",
      "+--------+-----+\n",
      "|  H35.32|  402|\n",
      "|  362.52|  395|\n",
      "|   E11.9|  244|\n",
      "| H35.033|  197|\n",
      "|H35.3220|  155|\n",
      "|  H25.13|  152|\n",
      "|  H35.81|  140|\n",
      "|H35.3290|  135|\n",
      "| H35.321|  127|\n",
      "| E11.331|  115|\n",
      "| H43.813|  106|\n",
      "|  362.51|   97|\n",
      "|  362.02|   85|\n",
      "|  362.07|   81|\n",
      "|  379.23|   76|\n",
      "|  362.35|   65|\n",
      "|  E78.00|   64|\n",
      "|  H18.59|   59|\n",
      "|  361.81|   58|\n",
      "| H04.123|   56|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spdf_dx.groupBy('dx_code').count().orderBy('count', ascending=False).show()\n",
    "#spdf_dx.select('dx_code').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-novel",
   "metadata": {},
   "source": [
    "## 1.3. Check the procedure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "offshore-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt_id</th>\n",
       "      <th>dos</th>\n",
       "      <th>procedure_code</th>\n",
       "      <th>mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>12/14/19</td>\n",
       "      <td>2027F</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026</td>\n",
       "      <td>11/13/19</td>\n",
       "      <td>92014</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026</td>\n",
       "      <td>11/6/19</td>\n",
       "      <td>G8427</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>10/2/19</td>\n",
       "      <td>92134</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>9/23/19</td>\n",
       "      <td>92014</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pt_id       dos procedure_code  mod\n",
       "0  10026  12/14/19          2027F  NaN\n",
       "1  10026  11/13/19          92014   25\n",
       "2  10026   11/6/19          G8427  NaN\n",
       "3  10026   10/2/19          92134  NaN\n",
       "4  10026   9/23/19          92014   25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pt_id              int64\n",
       "dos               object\n",
       "procedure_code    object\n",
       "mod               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5222, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pct = pd.read_csv(os.path.join(DATA_DIR, 'procedure.csv'), sep='\\t')\n",
    "data_pct.rename(columns={'patient_id': 'pt_id'}, inplace=True)\n",
    "data_pct.head()\n",
    "data_pct.dtypes\n",
    "data_pct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "negative-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5149, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pct.drop_duplicates(inplace=True)\n",
    "data_pct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "reflected-excerpt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt_id</th>\n",
       "      <th>dos</th>\n",
       "      <th>procedure_code</th>\n",
       "      <th>mod</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2027F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>92014</td>\n",
       "      <td>25</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>G8427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>92134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>92014</td>\n",
       "      <td>25</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pt_id        dos procedure_code  mod  year\n",
       "0  10026 2019-12-14          2027F  NaN  2019\n",
       "1  10026 2019-11-13          92014   25  2019\n",
       "2  10026 2019-11-06          G8427  NaN  2019\n",
       "3  10026 2019-10-02          92134  NaN  2019\n",
       "4  10026 2019-09-23          92014   25  2019"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the dos type to datatime and creat a new column of year \n",
    "data_pct[\"dos\"] = pd.to_datetime(data_pct['dos'])\n",
    "data_pct['year']=data_pct['dos'].dt.year\n",
    "data_pct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-timing",
   "metadata": {},
   "source": [
    "#### There are 86 procedure codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "invisible-customs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pt_id             932\n",
       "dos               685\n",
       "procedure_code     86\n",
       "mod                12\n",
       "year                7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "92134         757\n",
       "92014         581\n",
       "67028         474\n",
       "92012         442\n",
       "99213         250\n",
       "             ... \n",
       "J0178OU         1\n",
       "LUC5MG          1\n",
       "J2778-5         1\n",
       "J2778,05MG      1\n",
       "J3490           1\n",
       "Name: procedure_code, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['2027F', '92014', 'G8427', '92134', '2026F', '1036F', '92012',\n",
       "       '92226', 'EYLEAX1', '99213', '92015', '99212', '3072F', '2019F',\n",
       "       '4177F', '92083', '67210', '92250', 'C9257', '92235', 'G8397',\n",
       "       '92135', '99214', '76512', '67228', '92133', '2022F', '5010F',\n",
       "       '2024F', '4040F', '3284F', '92225', '67028', 'J2778PF', 'J3590',\n",
       "       'J9035', '92273', 'G8482', '67040', '92020', 'G8420', '99499',\n",
       "       '92136', 'G8950', '67028MCR', 'J0178OU', 'J0178', 'LACS', '92002',\n",
       "       '99024', 'G8753', 'LUC5SYRX1', 'G8756', 'G8754', 'G9974', 'J2778',\n",
       "       'J7312', '92242', '67041', '92081', 'G9744', '66984', 'J7999',\n",
       "       '3285F', '2021F', 'J2778-5', 'J2778,05MG', 'J2778-5P', 'G8752',\n",
       "       'AVASTIN', 'G9903', 'RS000', '66821', 'G8918', 'G8907', 'J3490',\n",
       "       '1', 'J9035,J3490,Q9977', 'D0000', '92283', 'J2778P', 'LUC5MG',\n",
       "       'G8428', 'J2778DME', '92240', 'J2778POU'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pct.apply(lambda x: len(x.unique()))\n",
    "data_pct.procedure_code.value_counts()\n",
    "data_pct['procedure_code'].unique()\n",
    "#data_pct.dos.value_counts()\n",
    "#data_pct.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "maritime-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Value Summary\n",
      "-----------------------------------\n",
      "pt_id                0\n",
      "dos                  0\n",
      "procedure_code       0\n",
      "mod               3709\n",
      "year                 0\n",
      "dtype: int64\n",
      "There were 3709 rows with missing values in data_pct dataset\n"
     ]
    }
   ],
   "source": [
    "#Check missing values in specified columns. Note the missing value in Treatment Plan is not counted. \n",
    "columns_to_check =['pt_id', 'dos', 'procedure_code', 'mod']\n",
    "row_with_missing = [row_idx for row_idx,row in data_pct[columns_to_check].isnull().iterrows() if True in row.values]\n",
    "print(\"\\nMissing Value Summary\\n{}\".format(\"-\"*35))\n",
    "print(data_pct.isnull().sum(axis = 0))\n",
    "if len(row_with_missing) > 0:\n",
    "    print(\"There were {} rows with missing values in data_pct dataset\".format(len(row_with_missing)))\n",
    "else:\n",
    "    print(\"There were no rows with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-blank",
   "metadata": {},
   "source": [
    "#### Fill missing values with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vocal-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pct = data_pct.fillna(\"NA\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "junior-profile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA          3709\n",
       "25           501\n",
       "RT           433\n",
       "LT           291\n",
       "24            68\n",
       "50            49\n",
       "79            35\n",
       "57            20\n",
       "8P            20\n",
       "59            10\n",
       "TC             8\n",
       "18944008       5\n",
       "Name: mod, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pct['mod'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-dairy",
   "metadata": {},
   "source": [
    "> -------------------------------------------------------------pyspark-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceramic-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------+----+\n",
      "|pt_id|     dos|procedure_code| mod|\n",
      "+-----+--------+--------------+----+\n",
      "|10026|12/14/19|         2027F|null|\n",
      "|10026|11/13/19|         92014|  25|\n",
      "|10026| 11/6/19|         G8427|null|\n",
      "|10026| 10/2/19|         92134|null|\n",
      "|10026| 9/23/19|         92014|  25|\n",
      "+-----+--------+--------------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- pt_id: integer (nullable = true)\n",
      " |-- dos: string (nullable = true)\n",
      " |-- procedure_code: string (nullable = true)\n",
      " |-- mod: string (nullable = true)\n",
      "\n",
      "5222 4\n"
     ]
    }
   ],
   "source": [
    "spdf_pct = spark.read.load(os.path.join(DATA_DIR, 'procedure.csv'), format='csv', sep='\\t', inferSchema=\"true\", header='true')\n",
    "spdf_pct = spdf_pct.withColumnRenamed('patient_id', 'pt_id')\n",
    "spdf_pct.show(5)\n",
    "spdf_pct.printSchema()\n",
    "print(spdf_pct.count(), len(spdf_pct.columns))\n",
    "#spdf_pct.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dietary-hudson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5149, 4)\n"
     ]
    }
   ],
   "source": [
    "spdf_pct = spdf_pct.dropDuplicates()\n",
    "#spdf_dx.show(5)\n",
    "print((spdf_pct.count(), len(spdf_pct.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "reliable-alcohol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------+----+----+\n",
      "|pt_id|     dos|procedure_code| mod|year|\n",
      "+-----+--------+--------------+----+----+\n",
      "|10482|12/28/18|         67028|  LT|2018|\n",
      "|14795| 1/17/19|         67028|null|2019|\n",
      "|15561|12/21/15|         3285F|null|2015|\n",
      "|16910|12/14/14|         92134|null|2014|\n",
      "|18796| 12/8/16|         4177F|null|2016|\n",
      "|18796| 7/13/16|         92134|null|2016|\n",
      "|19922|12/20/16|         92014|null|2016|\n",
      "|21853| 3/29/14|         1036F|null|2014|\n",
      "|25601| 9/15/16|         92134|null|2016|\n",
      "|25601| 9/27/17|         92134|  50|2017|\n",
      "|26375| 2/24/15|         92014|null|2015|\n",
      "|26660| 1/19/17|         2019F|null|2017|\n",
      "|26668| 8/20/13|         99214|null|2013|\n",
      "|27032|  9/2/15|         92014|null|2015|\n",
      "|27468| 7/11/13|         92134|null|2013|\n",
      "|31132|12/30/14|         G8427|null|2014|\n",
      "|34041|12/19/13|         92012|null|2013|\n",
      "|38768|10/16/18|         J9035|null|2018|\n",
      "|39498| 11/7/19|         92083|null|2019|\n",
      "|41892| 4/24/17|         92133|null|2017|\n",
      "+-----+--------+--------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf, year\n",
    "\n",
    "udf1 = udf(lambda x: '20'+x[-2:], StringType())\n",
    "spdf_pct = spdf_pct.withColumn('year',year(udf1('dos')))\n",
    "spdf_pct.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "entire-campaign",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import to_timestamp, col, unix_timestamp, to_date\n",
    "\n",
    "spdf_pct = spdf_pct.withColumn('date_in_dateFormat', to_date(unix_timestamp(col('dos'), 'M/D/yy').cast(\"timestamp\")))\n",
    "spdf_pct.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "timely-plumbing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+--------------+---+----+\n",
      "|pt_id|dos|procedure_code|mod|year|\n",
      "+-----+---+--------------+---+----+\n",
      "|    0|  0|             0|  0|   0|\n",
      "+-----+---+--------------+---+----+\n",
      "\n",
      "+-----+---+--------------+----+----+\n",
      "|pt_id|dos|procedure_code| mod|year|\n",
      "+-----+---+--------------+----+----+\n",
      "|    0|  0|             0|3709|   0|\n",
      "+-----+---+--------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col, isnull\n",
    "spdf_pct.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in spdf_pct.columns]).show()\n",
    "spdf_pct.select([count(when(col(c)=='null', c)).alias(c) for c in spdf_pct.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "vanilla-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|procedure_code|count|\n",
      "+--------------+-----+\n",
      "|         92134|  757|\n",
      "|         92014|  581|\n",
      "|         67028|  474|\n",
      "|         92012|  442|\n",
      "|         99213|  250|\n",
      "|         92226|  219|\n",
      "|         G8427|  180|\n",
      "|         99214|  160|\n",
      "|         J9035|  144|\n",
      "|         J0178|  132|\n",
      "|         1036F|  127|\n",
      "|         4177F|  118|\n",
      "|         2019F|  118|\n",
      "|         J2778|   83|\n",
      "|         2022F|   78|\n",
      "|         67210|   75|\n",
      "|         92250|   68|\n",
      "|         99499|   54|\n",
      "|         G8397|   50|\n",
      "|         5010F|   50|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+-----+\n",
      "|     mod|count|\n",
      "+--------+-----+\n",
      "|    null| 3709|\n",
      "|      25|  501|\n",
      "|      RT|  433|\n",
      "|      LT|  291|\n",
      "|      24|   68|\n",
      "|      50|   49|\n",
      "|      79|   35|\n",
      "|      8P|   20|\n",
      "|      57|   20|\n",
      "|      59|   10|\n",
      "|      TC|    8|\n",
      "|18944008|    5|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spdf_dx.dx_code.unique()\n",
    "spdf_pct.groupBy('procedure_code').count().orderBy('count', ascending=False).show()\n",
    "spdf_pct.groupBy('mod').count().orderBy('count', ascending=False).show()\n",
    "#spdf_dx.select('dx_code').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-investigator",
   "metadata": {},
   "source": [
    "#### There are 11 modifier codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-blackjack",
   "metadata": {},
   "source": [
    "# 2. Answers to questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-transparency",
   "metadata": {},
   "source": [
    "### Q1. What are the types of data quality issues or checks should you consider?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-range",
   "metadata": {},
   "source": [
    "Data quality checks include: \n",
    "* Duplicate data\n",
    "* Data with missing values \n",
    "* Data accuracy such as data range, closeness of data values with real-world values. \n",
    "* Data type and format\n",
    "* Consistency of data such as medical code over time or across sites\n",
    "* Data distribution and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-meditation",
   "metadata": {},
   "source": [
    "### Q2. How many patients have Wet Age-Related Macular Degeneration (wAMD) in the given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-enemy",
   "metadata": {},
   "source": [
    "> The Terminology of wet Age-Related Macular Degeneration (wAMD) is <span style=\"color:yellow\"> Exudative Age-related Macular Degeneration</span>, which uses \n",
    "H35.31xx for dry AMD, and H35.32xx for wet AMD in ICD-10-CM. The sixth character to indicate laterality as follows:\n",
    "> * 1 for the right eye\n",
    "> * 2 for the left eye\n",
    "> * 3 for bilateral\n",
    "\n",
    "> Its SNOMED concept code is 414173003 with the following relationship diagram  \n",
    "![The SNOMED expression for wAMD!](./diagram-414173003-2.png \"SNOMED CT expression\"):\n",
    "\n",
    "References:\n",
    "1. [AAO](https://www.aao.org/eyenet/article/how-to-use-the-icd-10-codes-for-amd)\n",
    "2. [CDC](https://icd10cmtool.cdc.gov/?fy=FY2021&q=h35.2)\n",
    "3. [SNOMED CT US](https://browser.ihtsdotools.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "impossible-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H35.32       0.089652\n",
       "362.52       0.088091\n",
       "E11.9        0.054416\n",
       "H35.033      0.043934\n",
       "H35.3220     0.034567\n",
       "H25.13       0.033898\n",
       "H35.81       0.031222\n",
       "H35.3290     0.030107\n",
       "H35.321      0.028323\n",
       "E11.331      0.025647\n",
       "H43.813      0.023640\n",
       "362.51       0.021632\n",
       "362.02       0.018956\n",
       "362.07       0.018064\n",
       "379.23       0.016949\n",
       "362.35       0.014496\n",
       "E78.00       0.014273\n",
       "H18.59       0.013158\n",
       "361.81       0.012935\n",
       "H04.123      0.012489\n",
       "H43.11       0.012043\n",
       "379.21       0.011374\n",
       "366.16       0.010928\n",
       "362.56       0.009144\n",
       "H25.9        0.008921\n",
       "H40.11X      0.008698\n",
       "362.31       0.008029\n",
       "362.16       0.008029\n",
       "E11.329      0.007806\n",
       "H52.4        0.007806\n",
       "374.3        0.007360\n",
       "H43.811      0.007360\n",
       "H43.13       0.007136\n",
       "H43.812      0.006913\n",
       "H31.093      0.006467\n",
       "375.15       0.006244\n",
       "E11.339      0.006021\n",
       "H35.059      0.005798\n",
       "373          0.005575\n",
       "365.11       0.005575\n",
       "H18.20       0.005575\n",
       "H52.13       0.005352\n",
       "H34.819      0.004906\n",
       "H40.033      0.004906\n",
       "362.83       0.004906\n",
       "H31.013      0.004906\n",
       "H18.51       0.004906\n",
       "362.05       0.004906\n",
       "E11.311      0.004906\n",
       "E11.319      0.004906\n",
       "362.36       0.004683\n",
       "H20.9        0.004460\n",
       "H26.493      0.004460\n",
       "H25.89       0.004460\n",
       "H02.403      0.004460\n",
       "362.81       0.004237\n",
       "E11.359      0.004237\n",
       "362.01       0.004014\n",
       "H35.051      0.003568\n",
       "362.11       0.003568\n",
       "H52.223      0.003122\n",
       "H34.231      0.003122\n",
       "367.4        0.003122\n",
       "H35.60       0.002899\n",
       "H40.021      0.002899\n",
       "H25.11       0.002899\n",
       "H21.01       0.002676\n",
       "H35.031      0.002676\n",
       "H43.391      0.002676\n",
       "H33.321      0.002676\n",
       "364.3        0.002676\n",
       "H16.223      0.002676\n",
       "368.8        0.002453\n",
       "E10.9        0.002453\n",
       "H35.31       0.002230\n",
       "365.74       0.002230\n",
       "365.7        0.002230\n",
       "H43.12       0.002230\n",
       "H53.2        0.002230\n",
       "371.2        0.002007\n",
       "362.32       0.002007\n",
       "363.32       0.002007\n",
       "362.53       0.001784\n",
       "E11.351      0.001784\n",
       "365.05       0.001784\n",
       "H35.61       0.001784\n",
       "H34.811      0.001784\n",
       "H00.023      0.001784\n",
       "H52.221      0.001784\n",
       "H35.40       0.001784\n",
       "H35.371      0.001784\n",
       "H34.12       0.001784\n",
       "H25.811      0.001784\n",
       "H54.7        0.001784\n",
       "H35.363      0.001561\n",
       "H25.012      0.001561\n",
       "H25.12       0.001561\n",
       "H35.3210     0.001561\n",
       "367.21       0.001338\n",
       "366.53       0.001338\n",
       "360.21       0.001338\n",
       "H35.3293     0.001115\n",
       "367.1        0.001115\n",
       "H35.3292     0.001115\n",
       "H35.3231     0.000892\n",
       "H40.013      0.000892\n",
       "H00.026      0.000892\n",
       "H54.8        0.000892\n",
       "E11.341      0.000892\n",
       "H35.032      0.000892\n",
       "H26.491      0.000892\n",
       "H40.89       0.000892\n",
       "H34.813      0.000892\n",
       "H35.323      0.000892\n",
       "H02.883      0.000892\n",
       "H35.352      0.000892\n",
       "H35.373      0.000892\n",
       "E11.39       0.000892\n",
       "H53.40       0.000892\n",
       "H35.723      0.000892\n",
       "H33.41       0.000892\n",
       "366.1        0.000892\n",
       "H35.372      0.000892\n",
       "H11.003      0.000892\n",
       "H40.9        0.000892\n",
       "H04.129      0.000892\n",
       "H04.122      0.000892\n",
       "368.4        0.000892\n",
       "H35.3291     0.000892\n",
       "H59.023      0.000892\n",
       "H21.1X1      0.000892\n",
       "368.9        0.000892\n",
       "H43.393      0.000892\n",
       "312912001    0.000669\n",
       "H35.3232     0.000669\n",
       "373.12       0.000669\n",
       "379.24       0.000446\n",
       "H35.3230     0.000446\n",
       "374.87       0.000446\n",
       "379.27       0.000446\n",
       "H18.50       0.000446\n",
       "365.1        0.000446\n",
       "H35321       0.000223\n",
       "h35.329      0.000223\n",
       "H35.3112     0.000223\n",
       "h35.321      0.000223\n",
       "414173003    0.000223\n",
       "60189009     0.000223\n",
       "H35.322      0.000223\n",
       "369.9        0.000223\n",
       "312956001    0.000223\n",
       "36252        0.000223\n",
       "Name: dx_code, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 160\n",
    "data_dx.dx_code.value_counts(normalize=True, sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-amazon",
   "metadata": {},
   "source": [
    "> ICD-9-CM code is 362.52, ICD-10-CM is H35.32XX, SNOMED CT Concept Code: 414173003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-counter",
   "metadata": {},
   "source": [
    "#### Checking if there is any multiple dx_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "naked-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The incidence of multiple dx_code is 0\n"
     ]
    }
   ],
   "source": [
    "#dx['dx_code'].str.split().str.len() \n",
    "print('The incidence of multiple dx_code is {}'.format(len([x for x in data_dx['dx_code'].str.split(\" |,\").str.len() if x>1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "crucial-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbe of records with Wet Age-Related Macular Degeneration (wAMD) diagnosis is: 1254\n",
      "The numbe of patients having Wet Age-Related Macular Degeneration (wAMD) is: 419\n"
     ]
    }
   ],
   "source": [
    "# h is the group of patients diagnozed with wAMD which is coded as H35.32XX and 362.52 in ICD-9-CM\n",
    "h=data_dx[data_dx['dx_code'].str.contains('H35.32|362.52|414173003|H3532|36252', case=False)]\n",
    "print('The numbe of records with Wet Age-Related Macular Degeneration (wAMD) diagnosis is: {}'.format(len(h)))\n",
    "print('The numbe of patients having Wet Age-Related Macular Degeneration (wAMD) is: {}'.format(len(set(h['pt_id']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-backing",
   "metadata": {},
   "source": [
    "> ---------------------------------------------pyspark---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-cisco",
   "metadata": {},
   "source": [
    "#### Checking if there is any multiple dx_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "subjective-doctor",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-34d59a082b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msdf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspdf_dx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dx_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" |,\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetItem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CodeNum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCodeNum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split' is not defined"
     ]
    }
   ],
   "source": [
    "sdf2=spdf_dx.select(split(col('dx_code'), \" |,\").getItem(1).alias('CodeNum'))\n",
    "sdf2.filter(sdf2.CodeNum.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "spdf_dx.registerTempTable('dx_table')\n",
    "sDF = sqlContext.sql('select count(DISTINCT pt_id)\\\n",
    "                    from dx_table \\\n",
    "                    where (upper(dx_code) LIKE upper(\"%H35.32%\") \\\n",
    "                    OR upper(dx_code) LIKE upper(\"%H3532%\") \\\n",
    "                    OR dx_code LIKE \"%362.52%\" \\\n",
    "                    OR dx_code LIKE \"%36252%\" \\\n",
    "                    OR dx_code LIKE \"%414173003%\" ) \\\n",
    "                     ')\n",
    "sDF.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "alive-slave",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import upper\n",
    "spdf_dx.select((upper(spdf_dx.dx_code).like(\"%H35.32%\") | upper(spdf_dx.dx_code).like(\"%362.52%\")).alias('wAMD')).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "h[h['dx_code']=='36252']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-classic",
   "metadata": {},
   "source": [
    "### Q3. How many patients have wAMD in 2019?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The numbe of patients having wAMD in 2019 is: {}'.format(len(set(h[h['year']==2019]['pt_id']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-bangkok",
   "metadata": {},
   "source": [
    "> ---------------------------------------------pyspark---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "spdf_dx.registerTempTable('dx_table')\n",
    "sDF = sqlContext.sql('select count(DISTINCT pt_id) \\\n",
    "                    from dx_table \\\n",
    "                    where (upper(dx_code) LIKE upper(\"%H35.32%\") OR dx_code LIKE \"%362.52%\" OR upper(dx_code) LIKE upper(\"%H3532%\")) \\\n",
    "                    AND year==2019 \\\n",
    "                     ')\n",
    "sDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-orleans",
   "metadata": {},
   "source": [
    "### Q4. How many patients have wAMD between 2014-2017, stratified by sex?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-painting",
   "metadata": {},
   "source": [
    "#### Building a subgroup of patients diagnosed wAMD between 2014 and 2017 by joining patient and diagnosis tables on patient id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_h_14to17 is the subgroup of patients diagnozed wAMD between 2014 and 2017 by joining patient data and diagnosis data on patient id\n",
    "pt_h = pd.merge(data_pt, h, on='pt_id', how='right')\n",
    "pt_h_14to17=pt_h[(pt_h['year']>=2014) & (pt_h['year']<=2017)]\n",
    "pt_h_14to17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The numbe of patients having Wet Age-Related Macular Degeneration (wAMD) between 2014 and 2017, stratified by sex')\n",
    "temp=pt_h_14to17.groupby(['sex'],as_index=False).agg(order=('pt_id', 'nunique'))\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-stack",
   "metadata": {},
   "source": [
    "> -------------------------------------------pyspark-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "spdf_pt.registerTempTable('pt_table')\n",
    "sdf = sqlContext.sql('select *\\\n",
    "                    from dx_table d JOIN pt_table p ON d.pt_id=p.pt_id \\\n",
    "                    where (upper(dx_code) LIKE upper(\"%H35.32%\") OR dx_code LIKE \"%362.52%\" OR upper(dx_code) LIKE upper(\"%H3532%\")) \\\n",
    "                    AND year BETWEEN 2014 AND 2017')\n",
    "sdf.show(5)\n",
    "#spdf_pct.groupBy('mod').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "sdf.groupby('unified_gender').agg(countDistinct('d.pt_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(temp['sex'], temp['order'], color=('red','steelblue','green'))\n",
    "plt.title('Patient with wAMD by Gender between 2014 and 2017')\n",
    "plt.ylabel('Numer of patient');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-adjustment",
   "metadata": {},
   "source": [
    "### Q5. How would you determine if sex is associated with an increased risk of wAMD?\n",
    "\n",
    "The total number of wAMD patients and the non-WAMD patient are calculated from patient and diagnosis data, stratified by sex. We perform a Chi-Square test to check whether there is any relationship between **Gender** and **wAMD**. \n",
    "\n",
    "1. Define the hypothesis:\n",
    "* Null Hypothesis: two variables are independent.\n",
    "* Alternate Hypothesis: two variables are not independent.\n",
    "\n",
    "2. Built the contingency table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid=set(h['pt_id'])\n",
    "pos=data_pt.set_index('pt_id').loc[pid, :].reset_index().groupby('sex').agg(cnt=('pt_id', 'nunique'))\n",
    "neg=data_pt.groupby('sex').agg(cnt=('pt_id', 'nunique'))-pos\n",
    "tab=pd.concat([pos.rename(columns={'cnt':'wAMD'}), neg.rename(columns={'cnt': 'non-wAMD'})], axis=1).iloc[:2,:]\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-satin",
   "metadata": {},
   "source": [
    "3. Calculate the Chi-square statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "chi2, pval, dof, expected = stats.chi2_contingency(observed=tab)\n",
    "print('The p-value of Chi-square test is {}'.format(pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-million",
   "metadata": {},
   "source": [
    "4. Results:\n",
    "\n",
    "With the currently available data, the association between sex and the risk of wAMD can be roughly calculated with Chi-square as shown above. Based on the p-value from the test, we'd accept the Null Hypothesis that there is no association between sex and the risk of wAMD.\n",
    "\n",
    "5. Discussions:\n",
    "\n",
    "However, such conclusion could be misleading for two reasons: \n",
    "* It didn’t take other confounding factors into account.\n",
    "* The sample may poorly represent the general population. \n",
    "\n",
    "To further estimate the association, random sampling in the general population and complete demographic data of the sample such as age, race, and medical history et al are necessary. Using supervised learning algorithms such as logistic regression, the association of individual parameters including sex with the risk of wAMD can be better evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-rocket",
   "metadata": {},
   "source": [
    "### Q6. How many women diagnosed with wAMD between 2014-2017 also had an intravitreal injection during that time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-james",
   "metadata": {},
   "source": [
    "#### Joining the subgroup of patients diagnosed with wAMD during 2014-2017 with procedure table on patient id and year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-footage",
   "metadata": {},
   "source": [
    " > <span style=\"color:red\">-----------------------------------WRONG Answer in python---------------------------------------------</span>\n",
    " * NOTE: Using the JOIN ON two keys, pt_id and year filtered out those records in which the diagnosis and injection procedure did not occured in the same year. such as example below: \n",
    " > pt_id\tdos_x\tprocedure_code\tmod\tyear_x\tsex\tdos_y\tdx_code\tyear_y\n",
    " \n",
    " > 1234\t10698\t2017-05-08\t4177F\tNA\t2017\tF\t2014-10-07\t362.52\t2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt_h_14to17 is the group having Wet Age-Related Macular Degeneration (wAMD) between 2014 and 2017,\n",
    "pt_h_pct_old = pd.merge(data_pct, pt_h_14to17, on=['pt_id','year'], how='inner')\n",
    "pt_h_pct_F_old=pt_h_pct_old[pt_h_pct_old['sex']=='F']\n",
    "pt_h_pct_F_old.shape\n",
    "pt_h_pct_F_old.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-calendar",
   "metadata": {},
   "source": [
    " > -----------------------------------Right Answer in python---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt_h_14to17 is the group having Wet Age-Related Macular Degeneration (wAMD) between 2014 and 2017,\n",
    "pt_h_pct = pd.merge(data_pct, pt_h_14to17, on=['pt_id'], how='inner')\n",
    "pt_h_pct_F=pt_h_pct[(pt_h_pct['sex']=='F') & (pt_h_pct['year_x']>=2014) & (pt_h_pct['year_x']<=2017)]\n",
    "pt_h_pct_F.shape\n",
    "pt_h_pct_F.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-lotus",
   "metadata": {},
   "source": [
    "#### The procedure code of intravitreal injection is **67028**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(pt_h_pct_F[pt_h_pct_F['procedure_code'].isin(['67028'])]['pt_id'])\n",
    "print('The number of women diagnosed with wAMD between 2014-2017 also had an intravitreal injection during the time is: {}'.\\\n",
    "      format(len(set(pt_h_pct_F[pt_h_pct_F['procedure_code'].isin(['67028'])]['pt_id']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-joshua",
   "metadata": {},
   "source": [
    "> ----------------------------------------------pyspark----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "spdf_pct.registerTempTable('pct_table')\n",
    "\n",
    "sdf_f = sqlContext.sql('select *\\\n",
    "                    from dx_table d JOIN pt_table p ON d.pt_id=p.pt_id JOIN pct_table pc ON p.pt_id=pc.pt_id \\\n",
    "                    where (upper(dx_code) LIKE upper(\"%H35.32%\") OR dx_code LIKE \"%362.52%\" OR upper(dx_code) LIKE upper(\"%H3532%\")) \\\n",
    "                    AND d.year BETWEEN 2014 AND 2017 \\\n",
    "                    AND pc.year BETWEEN 2014 AND 2017 AND pc.procedure_code LIKE \"%67028%\" \\\n",
    "                    AND unified_gender LIKE \"F\" \\\n",
    "                    ')\n",
    "sdf_f.show()\n",
    "sdf_f.groupBy('unified_gender').agg(countDistinct('d.pt_id')).show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compliant-premium",
   "metadata": {},
   "source": [
    "sdf_f.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-water",
   "metadata": {},
   "source": [
    "### Q7. What is the most common type of intravitreal injection in women diagnosed with wAMD between 2014-2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_h_pct_F[pt_h_pct_F['procedure_code'].isin(['67028'])]['mod'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-boring",
   "metadata": {},
   "source": [
    " > -----------------------------------pyspark---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_f.groupBy('mod').agg(count('pc.dos').alias('cnt_injection')).orderBy('cnt_injection').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-directory",
   "metadata": {},
   "source": [
    "* The most common type of intravitreal injection in women diagnosed with wAMD between 2014-2017 is RT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-presentation",
   "metadata": {},
   "source": [
    "### Q8. Stratify the type and count of intravitreal injections by eye laterality (right, left, unspecified) in 2014-2017 for patients with wAMD by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid=set(h['pt_id'])\n",
    "pos_pct=data_pct.set_index('pt_id').loc[pid, :].reset_index()\n",
    "tmp=pos_pct[(pos_pct['year']>=2014) & (pos_pct['year']<=2017) & (pos_pct['procedure_code'].isin(['67028']))].copy()\n",
    "#tmp=pos_pct[(pos_pct['year']>=2014) & (pos_pct['year']<=2017)].copy()\n",
    "tmp['mod'].unique()\n",
    "#df1=df0[df0['procedure_code'].isin(['67028'])].copy()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "automatic-ready",
   "metadata": {},
   "source": [
    "tmp.head(10)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-china",
   "metadata": {},
   "source": [
    "* '18944008' is the Right eye structure (body structure) in SNOMED-CT. \n",
    "* '50' indicates bilaterial injections, including right and left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['mod']=tmp['mod'].map(lambda x: x.replace('18944008','RT'))\n",
    "columns_to_show =['dos']\n",
    "pd.pivot_table(tmp, index = ['year', 'mod'], values=columns_to_show, aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-viking",
   "metadata": {},
   "source": [
    " > -----------------------------------pyspark---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_1417_new = sqlContext.sql('SELECT * \\\n",
    "                    FROM pct_table pc \\\n",
    "                    WHERE pc.year BETWEEN 2014 AND 2017 AND pc.procedure_code LIKE \"%67028%\" \\\n",
    "                    AND pc.pt_id in (SELECT pt_id \\\n",
    "                    FROM dx_table \\\n",
    "                    WHERE (upper(dx_code) LIKE upper(\"%H35.32%\") OR dx_code LIKE \"%362.52%\" OR upper(dx_code) LIKE upper(\"%H3532%\") )) \\\n",
    "                    ')\n",
    "sdf_1417_new.show()\n",
    "sdf_1417_new.printSchema()\n",
    "print((sdf_1417_new.count(), len(sdf_1417_new.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_1417_new.groupBy('pc.year', 'mod').agg(count('pc.dos')).orderBy('pc.year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-tender",
   "metadata": {},
   "source": [
    " > <span style=\"color:red\">-----------------------------------WRONG Answer in pyspark---------------------------------------------</span>\n",
    " \n",
    " * NOTE: Using JOIN ON patient ID, instead of finding the patient subgroup, resulted in duplication of procedure records for patient having multiple diagnosis, see the example as demostrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_1417_od = sqlContext.sql('select pc.pt_id as pc_pid, pc.year as pc_yr, mod, procedure_code, pc.dos as pc_dos, dx_code, d.dos as d_dos, d.year as d_yr \\\n",
    "                    from pct_table pc JOIN dx_table d ON d.pt_id=pc.pt_id \\\n",
    "                    where (upper(dx_code) LIKE upper(\"%H35.32%\") OR dx_code LIKE \"%362.52%\") \\\n",
    "                    AND pc.year BETWEEN 2014 AND 2017 \\\n",
    "                    AND pc.procedure_code LIKE \"%67028%\" \\\n",
    "                    ')\n",
    "#sdf_1417_od.show()\n",
    "print((sdf_1417_od.count(), len(sdf_1417_od.columns)))\n",
    "sdf_1417_od.groupBy('pc_yr', 'mod').agg(count('pc_dos')).orderBy('pc_yr').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "spdf_pct.filter(spdf_pct.pt_id=='49241').orderBy('dos').show()\n",
    "spdf_dx.filter(spdf_dx.pt_id=='49241').orderBy('dos').show()\n",
    "sdf_1417_od.filter(sdf_1417_od.pc_pid=='49241').orderBy('pc_dos').show()\n",
    "#sdf_1417_od.filter(sdf_1417_od.pt_id=='42834').orderBy('dos').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-promotion",
   "metadata": {},
   "source": [
    "### Q9. Find the ratio of patient diagnosis dates that have a corresponding procedure date? Does this ratio tell you anything about the data? If so, what might it indicate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_pct = pd.merge(data_dx, data_pct, on=['pt_id', 'dos'], how='left')\n",
    "dx_pct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check missing values in specified columns. \n",
    "columns_to_check =['procedure_code']\n",
    "row_with_missing = [row_idx for row_idx, row in dx_pct[columns_to_check].isnull().iterrows() if True in row.values]\n",
    "print(\"\\nMissing Value Summary\\n{}\".format(\"-\"*35))\n",
    "print(dx_pct.isnull().sum(axis = 0))\n",
    "print(dx_pct.iloc[row_with_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dx[data_dx['pt_id']==43502]\n",
    "data_pct[data_pct['pt_id']==43502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The ratio of patient diagnosis dates that have a corresponding procedure date is: {}'.format((len(dx_pct)-len(row_with_missing))/len(dx_pct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-spell",
   "metadata": {},
   "source": [
    "> ----------------------------------------pyspark ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "spdf_pct.printSchema()\n",
    "spdf_dx.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_all = sqlContext.sql('select d.pt_id AS ds_pid, d.dos AS ds_dos, pc.pt_id AS pc_pid, pc.dos AS pc_dos, procedure_code, pc.year AS pc_yr \\\n",
    "                    from dx_table d LEFT JOIN pct_table pc ON d.pt_id=pc.pt_id AND d.year=pc.year \\\n",
    "                    ')\n",
    "sdf_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=sdf_all.toPandas();\n",
    "print(pdf.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col, isnull\n",
    "sdf_all.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sdf_all.columns]).show()\n",
    "sdf_all.select([count(when(col(c)=='null', c)).alias(c) for c in sdf_all.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-society",
   "metadata": {},
   "source": [
    "* The ratio is close to 1, indicating that the majority of the patient received the procedure on the same day of the diagnosis. The patient data is complete in terms of procedures and diagnosis codes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-winner",
   "metadata": {},
   "source": [
    "### Q10. Are there any issues with the data? If so, what issues did you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-organization",
   "metadata": {},
   "source": [
    "The following data quality issues are found\n",
    "1. There are duplicate values in patient, diagnosis, and procedure data\n",
    "2. In patient table, the sex values are not standard.\n",
    "3. In patient table, there are 8 patient_ids having multiple sex values.\n",
    "4. There are missing modifier values in procedure table\n",
    "5. The medical terms used in the modifier in the procedure table are not consistent. For example, '18944008' and 'RT' are both referred to the Right eye structure\n",
    "6. Both ICD-9-CM and ICD-10-CM diagnosis code for wAMD are used in diagnosis table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-significance",
   "metadata": {},
   "source": [
    "### Q11. How would you define completeness of patient notes and how would you go about validating it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-establishment",
   "metadata": {},
   "source": [
    "The completeness of patient notes can be defined in three dimensions: \n",
    "* Documentation: patient notes contain all the observations during every patient clinical encounter. \n",
    "* Breadth: There are multiple types of data, including diagnoses, laboratory test results, medications, and procedure codes. \n",
    "* Density: Patient notes contain sufficient numbers and density of data points over the time. \n",
    "\n",
    "Based on the above definitions, data completeness can be evaluated as follows.  \n",
    "* To check if there is data point at every patient's encounter by validating different data sources. \n",
    "* To examine the necessary data types are present in patient records such as laboratory results, medication orders, diagnoses, sex, and date of birth. \n",
    "* To check the availability data points at each patient visits over time. \n",
    "\n",
    "Reference: \n",
    "* N.G. Weiskopf et al. / Journal of Biomedical Informatics 46 (2013) 830–836\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-updating",
   "metadata": {},
   "source": [
    "### Q12. If you were to build a threshold for acceptable data quality, what would you take into consideration and how would you approach it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-october",
   "metadata": {},
   "source": [
    "The data quality is often accessed in the following dimensions\n",
    "* Completeness: Presence of the necessary data\n",
    "* Consistency: Uniformity in data across different data sources, sites and providers. \n",
    "* Accuracy: Closeness of agreement between data value and the true value\n",
    "\n",
    "We can define metrics in the specific dimensions and measure those metrics to evaluate data quality. Some of working examples are:\n",
    "* Completeness can be measured by the presence of necessary data elements for the study, percent of missing values for a data element to define the completeness of the data. \n",
    "* Consistency can be measured by comparable proportions of relevant code across data sources \n",
    "* Accuracy can be measured by percent of data values found to be in error, percent of implausible values, percent of data values that do not conform to range expectations. \n",
    "\n",
    "Depending on the application and the objective, we can use some of above measures and prioritize them by assigning different weights to built a score to access  data quality.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-vacuum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
